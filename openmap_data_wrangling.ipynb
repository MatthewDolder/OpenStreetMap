{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map Data Wrangling Project\n",
    "    \n",
    "I chose the city of San Antonio, TX: https://www.openstreetmap.org/relation/253556\n",
    "\n",
    "The San Antonio osm download came from the overpass API: https://overpass-api.de/api/map?bbox=-99.0555,29.1863,-97.9802,29.7304\n",
    "\n",
    "OSM Filesize Uncompressed: 512MB\n",
    "\n",
    "I parsed the XML using cElementTree iterparse and pushed the records into a local MongoDB installation using PyMongo.\n",
    "Using Beautiful Soup 4, I scraped an HTML file from USPS containing street suffix abbreviations: https://pe.usps.com/text/pub28/28apc_002.htm\n",
    "\n",
    "A smaller OSM file is attached with the code submission.  It represents a few blocks of the city.\n",
    "\n",
    "The queries below are run against the larger dump of the entire city. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#connect to the database\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client[\"street_map_410\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Database for Statistics\n",
    "### 1. size of the file\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'564 MB'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataSize = str(round(db.command(\"dbstats\")[\"dataSize\"] / 1024 / 1024))\n",
    "display(dataSize + \" MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of users: 1,610'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_users = len(db.nodes.find({\"user\": {\"$exists\": 1}}, {\"user\": 1, \"_id\": 0}).distinct(\"user\"))\n",
    "display(\"number of users: \" + f'{num_users:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. number of nodes and ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nodes collection contains 2,386,694 documents.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ways collection contains 298,076 documents.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_nodes = (db.nodes.count_documents({}))\n",
    "num_ways = (db.ways.count_documents({}))\n",
    "display(\"nodes collection contains \" + f'{num_nodes:,}' + \" documents.\")\n",
    "display(\"ways collection contains \" + f'{num_ways:,}' + \" documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. number of residential streets in ways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of residential streets: 29,045'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "streets = len(db.ways.find({\"tag.highway\": \"residential\", \"tag.name\": {\"$exists\": 1}}, {\"tag.name\": 1, \"_id\": 0}).distinct(\"tag.name\"))\n",
    "display(\"number of residential streets: \" + f'{streets:,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. number and types of highway nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': {'k': 'highway', 'v': 'turning_circle'}, 'count': 13782},\n",
       " {'_id': {'k': 'highway', 'v': 'traffic_signals'}, 'count': 2797},\n",
       " {'_id': {'k': 'highway', 'v': 'street_lamp'}, 'count': 2176},\n",
       " {'_id': {'k': 'highway', 'v': 'crossing'}, 'count': 2075},\n",
       " {'_id': {'k': 'highway', 'v': 'turning_loop'}, 'count': 851},\n",
       " {'_id': {'k': 'highway', 'v': 'stop'}, 'count': 815},\n",
       " {'_id': {'k': 'highway', 'v': 'give_way'}, 'count': 114},\n",
       " {'_id': {'k': 'highway', 'v': 'motorway_junction'}, 'count': 20},\n",
       " {'_id': {'k': 'highway', 'v': 'bus_stop'}, 'count': 14},\n",
       " {'_id': {'k': 'highway', 'v': 'mini_roundabout'}, 'count': 8},\n",
       " {'_id': {'k': 'highway', 'v': 'construction'}, 'count': 2},\n",
       " {'_id': {'k': 'highway', 'v': 'services'}, 'count': 1},\n",
       " {'_id': {'k': 'highway', 'v': 'checkpoint'}, 'count': 1}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reference: https://pymongo.readthedocs.io/en/stable/examples/aggregation.html\n",
    "\n",
    "from bson.son import SON\n",
    "pipeline = [\n",
    "            {\"$unwind\": \"$tag\"},\n",
    "            {\"$match\": {\"tag.k\":\"highway\"}},\n",
    "            {\"$group\": {\"_id\": \"$tag\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "            ]\n",
    "tags = db.nodes.aggregate(pipeline)\n",
    "display(list(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. number of document submissions per year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021:160489'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2020:472031'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2019:414132'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2018:151831'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2017:138396'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2016:95203'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2015:182256'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2014:97784'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2013:68244'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2012:159966'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2011:91342'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2010:34821'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2009:318009'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008:2190'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#source: https://pymongo.readthedocs.io/en/stable/examples/aggregation.html\n",
    "#https://docs.mongodb.com/manual/aggregation/\n",
    "from bson.son import SON\n",
    "\n",
    "pipeline = [{\"$project\": {\"_id\" : 0,\"year\":{\"$substrBytes\":[\"$timestamp\",0,4]}}},\n",
    "            {\"$group\" : {\"_id\" : \"$year\",\"numdocs\":{\"$sum\": 1}}},\n",
    "            {\"$sort\" : {\"_id\":-1}}\n",
    "           ]\n",
    "\n",
    "years = db.nodes.aggregate(pipeline)\n",
    "for y in years:\n",
    "    display(y[\"_id\"] + \":\" + str(y[\"numdocs\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the enclosed python project\n",
    "\n",
    "To execute the project run `main.py`. This connects to a local MongoDB instance and sets up the database.  \n",
    "\n",
    "`openXML.parseXML(db,filepath)` is called next which uses cElementTree to parse the OSM file, create JSON records and push them into Mongo into one of three collections (nodes, ways, relations). \n",
    "\n",
    "A sample json document for a way: \n",
    "\n",
    "```Json \n",
    "{'id': '15110885', 'version': '11', 'timestamp': '2021-02-17T11:51:08Z', 'changeset': '99449870', 'uid': '10271447', 'user': 'grandhs', 'nd': ['149258796', '149258798'], 'tag': {'highway': 'residential', 'name': 'Lakeside Drive', 'tiger:cfcc': 'A41', 'tiger:county': 'Bandera, TX', 'tiger:name_base_1': 'Lakeside', 'tiger:name_type': 'Dr', 'tiger:reviewed': 'no'}}\n",
    "```\n",
    "\n",
    "Database populated, I create a pyMongo query to find all residential highways:\n",
    "```Json\n",
    "{\"tag.highway\": \"residential\", \"tag.name\": {\"$exists\": 1}}\n",
    "```\n",
    "\n",
    "Function `clean_streets.getCleanStreets(db,query)` is called which runs the Mongo query and creates a distinct list of street names.  Function `abbreviation_map.getReplacements` scrapes the list of postal suffixes and builds regex. \n",
    "\n",
    "For each unique street name, I run the list of regex commands.  If a match is found, it is returned back to main as a dictionary of search and replace shown below: \n",
    "\n",
    "The code block below runs through the query and clean process and outputs the list of cleaned residental streets for San Antonio, TX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balcon Is  :  Balcon Island\n",
      "Blanco Ky  :  Blanco Key\n",
      "Creek Cor  :  Creek Corner\n",
      "Falcons Ht  :  Falcons Heights\n",
      "Fawn Mnt  :  Fawn Mount\n",
      "Nike CIrcle  :  Nike Circle\n",
      "Oilfield Rds  :  Oilfield Roads\n",
      "Painted Tracks  :  Painted Track\n",
      "Reading Green Blvd  :  Reading Green Boulevard\n",
      "Sandoval street  :  Sandoval Street\n",
      "Scaup court  :  Scaup Court\n",
      "Sulphur Trails  :  Sulphur Trail\n",
      "Sunnyview Trails  :  Sunnyview Trail\n",
      "WInding RIver  :  WInding River\n",
      "Wetmore Knl  :  Wetmore Knoll\n",
      "Wild Trls  :  Wild Trail\n",
      "Wind river  :  Wind River\n",
      "glag lane  :  glag Lane\n",
      "loving path  :  loving Path\n"
     ]
    }
   ],
   "source": [
    "import clean_streets\n",
    "query = {\"tag.highway\": \"residential\", \"tag.name\": {\"$exists\": 1}}\n",
    "cleanstreets = clean_streets.getCleanStreets(db,query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to call `clean_streets.CleanTheStreets(cleanstreets,db)` which accepts the dictionary of old and new street names.  It steps through each one and runs a search and replace in Mongo: \n",
    "\n",
    "```Python\n",
    "for old,new in cleanstreets.items():\n",
    "        db.ways.update_many({\"tag.highway\": \"residential\", \"tag.name\": old}, {\"$set\": {\"tag.name\": new}})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems encountered\n",
    "\n",
    "### 1. memory errors\n",
    "The first pass I used cElementtree without iterparse.  This worked great for small datasets, however when I tried to process all of San Antonio, I ran into errors.  I then switched to iterparse and used the clear() method after each node. \n",
    "\n",
    "### 2. weird HTML table\n",
    "The HTML table scraped from the USPS site is in a strange format.  The result was a list of dictionaries where the first record has 3 columns, the next several records had only 1 column, etc.  To fix, I had to iterate through the list and create a fresh dictionary repeating the values in the first column.  A sample of the final set: \n",
    "```json\n",
    "{'ALLEE': 'Alley', 'ALLEY': 'Alley', 'ALLY': 'Alley', 'ALY': 'Alley', 'ANEX': 'Anex', 'ANNEX': 'Anex', 'ANNX': 'Anex', 'ANX': 'Anex', 'AV': 'Avenue', 'AVE': 'Avenue'}\n",
    "```\n",
    "\n",
    "### 3. Bad suffix\n",
    "The \"Arc\" suffix was turning streets which were supposed to end in \"Arc\" into \"Arcade\".  I removed this suffix.  \n",
    "\n",
    "### 4. performance problems itterating the list of street names X the list of known suffixes\n",
    "After some debugging, I found I was performing the HTML scrape for every street name.  Removing that made the performance good enough for the San Antonio dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Improvement\n",
    "\n",
    "### 1. Expanding the type of streets\n",
    "\n",
    "I limited the clean up to highway = residental.  The cleanup could be expanded for all highway types.  However, the USPS codes don't work well with business names.  For instance the \"Panda Express\" service road is changed into \"Panda Expressway\".  Some exceptions would need to be included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': {'highway': 'service', 'name': 'Panda Express'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "streets = db.ways.find({\"tag.highway\": \"service\", \"tag.name\": \"Panda Express\"}, {\"tag.highway\" : 1,\"tag.name\": 1, \"_id\": 0})\n",
    "for s in streets:\n",
    "    display(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By querying the database and adding to the filter, I was able to include other highway types including service roads while eliminating business names and private roads.  This found 1,692 candidates for cleanup and of those found 4 roads to clean.  Shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Street Name Candiates for Cleanup: 1692'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query={\"tag.highway\":{\"$in\":['living_street','motorway','motorway_link','path','primary','primary_link','proposed','secondary','secondary_link','service','tertiary','tertiary_link','trunk','trunk_link']}, \n",
    "       \"tag.access\":{\"$ne\":\"private\"}, \n",
    "       \"tag.name\":{\"$exists\":1, \"$ne\":\"Private Road\"},\n",
    "       \"tag.service\":{\"$ne\":\"drive-through\"}}\n",
    "streets = db.ways.find(query).distinct(\"tag.name\")\n",
    "display(\"Street Name Candiates for Cleanup: \" + str(len(streets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jagge lane  :  Jagge Lane\n",
      "Unnamed Pr  :  Unnamed Prairie\n",
      "Valley Trails  :  Valley Trail\n",
      "plantation drive  :  plantation Drive\n"
     ]
    }
   ],
   "source": [
    "cleanstreets = clean_streets.getCleanStreets(db,query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of the approach above is that a larger dataset, such as all of Texas,  will likely produce more edge cases.  That will require more adjustments to the filter.  \n",
    "\n",
    "### 2. Cleaning up municipal services\n",
    "San Antonio Fire Stations are not in a consistant format.  We could do a regex search and replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'San Antonio Fire Department Station #22': 'San Antonio Fire Station #22',\n",
       " 'San Antonio Fire Department Station Number 38': 'San Antonio Fire Station #38',\n",
       " 'San Antonio Fire Station #19': 'San Antonio Fire Station #19',\n",
       " 'San Antonio Fire Station #29': 'San Antonio Fire Station #29',\n",
       " 'San Antonio Fire Station #41': 'San Antonio Fire Station #41',\n",
       " 'San Antonio Fire Station 1': 'San Antonio Fire Station #1',\n",
       " 'San Antonio Fire Station 11': 'San Antonio Fire Station #11',\n",
       " 'San Antonio Fire Station 27': 'San Antonio Fire Station #27',\n",
       " 'San Antonio Fire Station 31': 'San Antonio Fire Station #31',\n",
       " 'San Antonio Fire Station 32': 'San Antonio Fire Station #32',\n",
       " 'San Antonio Fire Station 34': 'San Antonio Fire Station #34',\n",
       " 'San Antonio Fire Station 35': 'San Antonio Fire Station #35',\n",
       " 'San Antonio Fire Station 4': 'San Antonio Fire Station #4',\n",
       " 'San Antonio Fire Station 40': 'San Antonio Fire Station #40',\n",
       " 'San Antonio Fire Station 43': 'San Antonio Fire Station #43',\n",
       " 'San Antonio Fire Station 46': 'San Antonio Fire Station #46',\n",
       " 'San Antonio Fire Station 47': 'San Antonio Fire Station #47',\n",
       " 'San Antonio Fire Station 54': 'San Antonio Fire Station #54',\n",
       " 'San Antonio Fire Station No. 45': 'San Antonio Fire Station #45'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "#Reference: \n",
    "#https://stackoverflow.com/questions/55617412/how-to-perform-wildcard-searches-mongodb-in-python-with-pymongo\n",
    "fire = db.ways.find({\"tag.name\": {\"$regex\": \"San Antonio Fire.+\\d$\"}}).distinct(\"tag.name\")\n",
    "\n",
    "p = re.compile('.+?(\\d+)')\n",
    "\n",
    "firere = {}\n",
    "for f in fire:\n",
    "    if p.match(f):\n",
    "        firere[f] = \"San Antonio Fire Station #\" + p.match(f).group(1)\n",
    "display(firere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of the approach above is that it won't work for other cities.  An improvement would be to pull the city name from the database dynamically.  Also, many towns will only have 1 fire station which may not have a number at the end.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Finding new roads\n",
    "\n",
    "San Antonio is going through a period of rapid expansion.  It is easy to drive to a new neighborhood and confuse Google Maps.  However, realtors and builders are quick to list street names to new lots on real estate websites.  Here is one such development on Zillow: https://www.zillow.com/community/valley-ranch/29261528_plid/ The streets listed here do not show up on open street map search. \n",
    "\n",
    "It would be interesting project to scrape the popular real estate websites and list nodes and ways which need to be added to open street map.  Possibly the builders would be willing to provide a feed which could be cleaned and added automatically.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
